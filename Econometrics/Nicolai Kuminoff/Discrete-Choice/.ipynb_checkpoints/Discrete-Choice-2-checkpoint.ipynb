{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44eb29b8-9f22-425e-99f6-609ec0c4aa63",
   "metadata": {},
   "source": [
    "# Binary Response Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f6aba-db6f-4039-814b-a9c9ba181064",
   "metadata": {},
   "source": [
    "## 2A. Binary Response Framework\n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "- Model assumptions are analogous to MLR.1-MLR.6\n",
    "\n",
    "    - Model is correctly specified\n",
    "    \n",
    "    - Random sample from the population\n",
    "    \n",
    "    - Conditional variation in each explanatory variable\n",
    "    \n",
    "    - Zero conditional mean\n",
    "    \n",
    "    - Homoskedasticity (or robust standard errors)\n",
    "    \n",
    "    - Assumption about the error distribution (e.g. normal, logistic)\n",
    "    \n",
    "-  Goal: Learn how $x_1, x_2, ..., x_k$ affect probability of making a choice \n",
    "\n",
    "- Simplyfying notation:\n",
    "\n",
    "    - Let $X\\beta = \\beta_0 + \\beta_0x_1 + ... + \\beta_0x_k$\n",
    "    \n",
    "    - Let $X = 1, x_1, x_2, ..., x_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2af36-8b74-48a4-9179-94272881b7ba",
   "metadata": {},
   "source": [
    "### Latent variable model\n",
    "\n",
    "- Let $c$ be a latent (i.e. unobserved) continuous choice variable such that:\n",
    "\n",
    "    - $y=1$ if $c = X\\beta + u > 0$\n",
    "    \n",
    "    - $y=0$ if $c = X\\beta + u \\leq 0$\n",
    "    \n",
    "    - $u$ is the econometric error\n",
    "\n",
    "- Let $p$ be the response probability $0 \\leq p \\leq 1$\n",
    "    \n",
    "- The probability that $y = 1$:\n",
    "$$p = p(y = 1|X)$$\n",
    "$$p  = p(c > 0 | X)$$\n",
    "$$p  = p(X\\beta + u> 0 | X)$$\n",
    "$$p = p(u > - X\\beta|X)$$\n",
    "$$p = f(X\\beta)$$\n",
    "    \n",
    "- The shape of the $f(X\\beta)$ function depends on the distribution of $u$\n",
    "\n",
    "    - Probit model: $u$ ~ standard normal\n",
    "    \n",
    "    - Logit model: $u$ ~ standard logistic\n",
    "    \n",
    "- The standard logistic distribution is symmetric, like the normal, but with fatter tails.\n",
    "\n",
    "<img src=\"images/normal-logistic.png\" alt=\"Distribution: Normal vs Logistic\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4257eae-ceb6-43d4-88c2-aceaacb7bd1d",
   "metadata": {},
   "source": [
    "## 2B. Binary Probit and Logit Models\n",
    "\n",
    "### Logit Model:\n",
    "\n",
    "$$p(y = 1|X) = f(X\\beta) = \\frac{e^{X\\beta}}{1 + e^{X\\beta} }$$\n",
    "\n",
    "Notice:\n",
    "\n",
    "   - $f\\rightarrow 0$ as $X\\beta \\rightarrow -\\infty$\n",
    "   \n",
    "   - $f\\rightarrow 1$ as $X\\beta \\rightarrow \\infty$\n",
    "    \n",
    "<img src=\"images/logit.png\" alt=\"Logit\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd111f64-c676-47ce-86aa-8d216a64fef0",
   "metadata": {},
   "source": [
    "#### Calculating Marginal Effects\n",
    "\n",
    "$$p(y = 1|X) = f(X\\beta) = \\frac{e^{X\\beta}}{1 + e^{X\\beta} }$$\n",
    "\n",
    "**Example:** Suppose $p$ depends on two variables $x_1$ and $x_2$.\n",
    "\n",
    "   - The values of $x_1$ and $x_2$. Let's set $x_2$ at its average: $x_2 = \\overline{x_2}.$ \n",
    "   \n",
    "   - Let's calculate the **change** in $p$ *increasing* $x_1$ *from $1$ to $2$*.\n",
    "   \n",
    "$$\\Delta p=  p(y = 1|x_1 = 2, x_2 = \\overline{x_2}) -p(y = 1|x_1 = 1, x_2 = \\overline{x_2}) $$\n",
    "\n",
    "\n",
    "$$\\Delta p=\n",
    "\\frac{e^{\\beta_0 + \\beta_12 + \\beta_2\\overline{x_2}}}{1 + e^{\\beta_0 + \\beta_12 + \\beta_2\\overline{x_2}}} = \\frac{e^{\\beta_0 + \\beta_1 + \\beta_2\\overline{x_2}}}{1 + e^{\\beta_0 + \\beta_1 + \\beta_2\\overline{x_2}}}$$\n",
    "\n",
    "**Note:** the answer would be different for increasing $x_1$ from $2$ to $3$ because of the non linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c277b-f136-4e5d-b3b2-489c734afbee",
   "metadata": {},
   "source": [
    "### Probit Model\n",
    "\n",
    "<img src=\"images/probit.png\" alt=\"Probit\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b1b26-e277-45d4-a1e6-10b2f4ba963c",
   "metadata": {},
   "source": [
    "## 2C. Maximum Likelihood Estimation \n",
    "\n",
    "- Unlike OLS we must know the distribution of the error term to implement maximum likelihood estimation.\n",
    "\n",
    "- Intuition for MLE: Choose values for the $\\beta's$ that maximize the likelihood of observing outcomes in your data.\n",
    "\n",
    "- **Likelihood function:** $$f(X_i\\beta)^{y_i}[1 - f(X_i\\beta)]^{(1- y_i)}$$\n",
    "\n",
    "- **Log-likelihood function (LLF):**\n",
    "\n",
    "$$\\lambda_i(\\beta) = y_iln[f(X_i\\beta)] + (1-y_i)ln[1- f(X_i\\beta)],$$\n",
    "\n",
    "where $\\lambda_i$ represents a particular value of the function for observation $i$\n",
    "    \n",
    "- **Estimation:** Choose $\\hat{\\beta}$ to maximize sum of the values of log-likelihood function, $L$.\n",
    "\n",
    "$$L =\\sum_{i=1}^{n}\\lambda_i(\\beta)$$\n",
    "\n",
    "**Note: Larger values for LLF imply more accurate predictions for $y_i$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e52b96-a81b-4098-88d9-1405df969d08",
   "metadata": {},
   "source": [
    "### Perfect Prediction\n",
    "\n",
    "#### *Case 1: Perfect Prediction* $y_i = 1 = f(X_i\\hat{\\beta})$\n",
    "\n",
    "Suppose the LLF predicts the outcomes of the data that we observe perfectly. That means if an agent choses to participate (the value of data is 1), the binary choice model correctly predicts with probability $1$: \n",
    "\n",
    "$$y_i = 1 = f(X_i\\hat{\\beta})$$\n",
    "\n",
    "Then LLF becomes\n",
    "\n",
    "\n",
    "$$\\lambda_i(\\beta) = y_iln[f(X_i\\beta)] + (1-y_i)ln[1- f(X_i\\beta)]$$\n",
    "\n",
    "\n",
    "$$\\lambda_i(\\beta) = y_i\\underbrace{ln[f(X_i\\beta)]}_{0} + \\underbrace{(1-y_i)}_{0}ln[1- f(X_i\\beta)],$$\n",
    "\n",
    "**That is, LLF takes on a value of zero when the model predicts correctly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307937b3-e2ae-47d4-9036-ed61eb34221f",
   "metadata": {},
   "source": [
    "#### *Case 2: Perfect Prediction* $y_i = 0 = f(X_i\\hat{\\beta})$\n",
    "\n",
    "When an agent choses not to participate (the value of data is 0), the binary choice model correctly predicts with probability $1$: \n",
    "\n",
    "$y_i = 0 = f(X_i\\hat{\\beta})$\n",
    "\n",
    "Then LLF becomes\n",
    "\n",
    "\n",
    "$$\\lambda_i(\\beta) = y_iln[f(X_i\\beta)] + (1-y_i)ln[1- f(X_i\\beta)]$$\n",
    "\n",
    "$$\\lambda_i(\\beta) = \\underbrace{y_i}_{0}ln[f(X_i\\beta)] + (1-y_i)\\underbrace{ln[1- f(X_i\\beta)]}_{0}$$\n",
    "\n",
    "\n",
    "\n",
    "**That is, LLF takes on a value of zero when the model predicts correctly.**\n",
    "\n",
    "**Pefect prediction implies 0 values for LLF: $\\lambda_i(\\hat{\\beta}) = 0$**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ce3cad-fd56-4881-88cc-7363e434ebdf",
   "metadata": {},
   "source": [
    "### Imperfect Prediction\n",
    "\n",
    "#### *Case 1* \n",
    "\n",
    "$$y_i = 1 > f(X_i\\hat{\\beta})$$\n",
    "\n",
    "- Actual value is $1$\n",
    "\n",
    "- Model predicts less than $1$\n",
    "\n",
    "\n",
    "LLF becomes:\n",
    "$$\\lambda_i(\\beta) = \\underbrace{y_i}_{1}\\underbrace{ln[f(X_i\\beta)]}_{\\text{negative}} + \\underbrace{(1-y_i)}_{0}ln[1- f(X_i\\beta)]$$\n",
    "\n",
    "\n",
    "\n",
    "We just have the first term, which is **negative**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fa864-c5eb-46ac-b421-cd81fc383c09",
   "metadata": {},
   "source": [
    "#### *Case 2* \n",
    "\n",
    "$$y_i = 0 < f(X_i\\hat{\\beta})$$\n",
    "\n",
    "- Actual value is $0$\n",
    "\n",
    "- Model predicts greater than $0$\n",
    "\n",
    "LLF becomes:\n",
    "$$\\lambda_i(\\beta) = \\underbrace{y_i}_{0}ln[f(X_i\\beta)] + \\underbrace{(1-y_i)}_{1}\\underbrace{ln[1- f(X_i\\beta)]}_{\\text{negative}}$$\n",
    "\n",
    "We just have the second term, which is **negative**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145b94b-2f6d-499a-b667-99d2de938be9",
   "metadata": {},
   "source": [
    "### Hypothesis Testing for MLE\n",
    "\n",
    "- z-tests (similar to OLS t-tests)\n",
    "\n",
    "- Wald statistics (similar to OLS F-tests)\n",
    "\n",
    "- Confidene intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9323c-816f-4aad-8163-42053771a362",
   "metadata": {},
   "source": [
    "### Goodness of Fit - pseudo R-squared\n",
    "\n",
    "- Pseudo $R^2 = 1 - \\frac{L_{UR}}{L_0}$\n",
    "    - where $L_0$ is (constant) for the LFF with intercept only\n",
    "    \n",
    "- As $L_{UR}$ increases, $L_{UR} \\rightarrow 0$\n",
    "    - which implies $\\frac{L_{UR}}{L_0} \\rightarrow 0$ and Pseudo $R^2 \\rightarrow 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2d130-1131-40bf-9b3f-6b522829290d",
   "metadata": {},
   "source": [
    "###  Potential Problems\n",
    "\n",
    "- Heteroskedasticity\n",
    "\n",
    "- Nonrandom samples\n",
    "\n",
    "- Violation of the zero conditional mean\n",
    "\n",
    "- Incorrect assumption about model error\n",
    "\n",
    "These can cause MLE to be biased and inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a8ee8-a276-4b41-b448-fc14b5795d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
